{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from skimage import io, feature\n",
    "from skimage.color import rgb2gray\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "Developed for Shopee Code League 2020<br>\n",
    "The purpose of this notebook is to build a image classification model for multi-label image dataset.<br>\n",
    "The dataset provided is not given/shown for confidentiality reasons\n",
    "\n",
    "<br>\n",
    "<b>To change the dimensions, change the variable PIXEL</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105392, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename\n",
       "category          \n",
       "0             2683\n",
       "1             2702\n",
       "2             2687\n",
       "3             2703\n",
       "4             2703\n",
       "5             2641\n",
       "6             2641\n",
       "7             2660\n",
       "8             2700\n",
       "9             2698\n",
       "10            2672\n",
       "11            1843\n",
       "12            2691\n",
       "13            2682\n",
       "14            2684\n",
       "15            2632\n",
       "16            2665\n",
       "17            1553\n",
       "18            2103\n",
       "19            2679\n",
       "20            2653\n",
       "21            2598\n",
       "22            2623\n",
       "23            2540\n",
       "24            2705\n",
       "25            2692\n",
       "26            2684\n",
       "27            2702\n",
       "28            2561\n",
       "29            2138\n",
       "30            2705\n",
       "31            2677\n",
       "32            2157\n",
       "33             573\n",
       "34            2599\n",
       "35            2658\n",
       "36            2686\n",
       "37            1725\n",
       "38            2673\n",
       "39            2678\n",
       "40            2681\n",
       "41            2662"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"datasets/product detection dataset/train.csv\")\n",
    "test = pd.read_csv(\"datasets/product detection dataset/test.csv\")\n",
    "train = train.sort_values(by=['category'])\n",
    "train = train.reset_index(drop=True)\n",
    "CAT_COUNT = train.groupby(['category']).count()\n",
    "categories = list(range(0, 42))\n",
    "PIXEL = 20\n",
    "print(train.shape)\n",
    "CAT_COUNT.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting images into standard pixel format and into an array (TRAIN DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImageToArray(array_counter, i, category):\n",
    "    # the string here needs to change according to the relative path of where you save your dataset\n",
    "    string = \"datasets/product detection dataset/train\"\n",
    "    if len(str(category))==1:\n",
    "        string += \"/\"+\"0\"+str(category)+\"/\"+train.iloc[i,0]\n",
    "    else:\n",
    "        string += \"/\"+str(category)+\"/\"+train.iloc[i,0]\n",
    "    # Change the values in the resize method to reflect your given dimensions/pixels\n",
    "    temp = np.array(Image.open(string).convert('L').resize((PIXEL,PIXEL)))\n",
    "    train_img[array_counter] = temp\n",
    "    \n",
    "def convertArrayToTxtFile(cat_array, category):\n",
    "    #Change the file below to reflect our given dimension/pixel\n",
    "    if len(str(category))==1:\n",
    "        filename = \"datasets/product detection dataset/train_array/train_img\"+\"0\"+str(category)+\".txt\"\n",
    "    else:\n",
    "        filename = \"datasets/product detection dataset/train_array/train_img\"+str(category)+\".txt\"\n",
    "    with open(filename, 'w') as outfile:\n",
    "        outfile.write('# Array shape: {0}\\n'.format(cat_array.shape))\n",
    "        for data_slice in cat_array:\n",
    "            np.savetxt(outfile, data_slice, fmt='%-7.2f')\n",
    "            outfile.write('# New slice\\n')\n",
    "    #print(\"txt file writing complete\")\n",
    "\n",
    "CAT_COUNT = train.groupby(['category']).count()\n",
    "cat = 0\n",
    "array_counter = 0\n",
    "train_img = np.empty([CAT_COUNT.iloc[0,0], PIXEL, PIXEL])\n",
    "for i in range(train.shape[0]):\n",
    "    if cat==train.iloc[i,1]:\n",
    "        convertImageToArray(array_counter, i, cat)\n",
    "        array_counter+=1\n",
    "    else:\n",
    "        #print(\"Category completed: \", cat)\n",
    "        convertArrayToTxtFile(train_img, cat)\n",
    "        array_counter = 0\n",
    "        cat = train.iloc[i,1]\n",
    "        train_img = np.empty([CAT_COUNT.iloc[cat, 0], PIXEL, PIXEL])\n",
    "        convertImageToArray(array_counter, i, cat)\n",
    "        \n",
    "with open(\"datasets/product detection dataset/train_array/train_img41.txt\", 'w') as outfile:\n",
    "    outfile.write('# Array shape: {0}\\n'.format(train_img.shape))\n",
    "    for data_slice in train_img:\n",
    "        np.savetxt(outfile, data_slice, fmt='%-7.2f')\n",
    "        outfile.write('# New slice\\n')\n",
    "#print(\"Final txt file writing complete\")\n",
    "print(\"Data writing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting images into standard pixel format and into an array (TEST DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImageToArray(i):\n",
    "    # the string here needs to change according to the relative path of where you save your dataset\n",
    "    string = \"datasets/product detection dataset/test/\"+test.iloc[i,0]\n",
    "    # Change the values in the resize method to reflect your given dimensions/pixels\n",
    "    temp = np.array(Image.open(string).convert('L').resize((PIXEL,PIXEL)))\n",
    "    test_img[i] = temp\n",
    "    \n",
    "def convertArrayToTxtFile(cat_array):\n",
    "    #Change the file below to reflect our given dimension/pixel\n",
    "    filename = \"datasets/product detection dataset/test_img.txt\"\n",
    "    with open(filename, 'w') as outfile:\n",
    "        outfile.write('# Array shape: {0}\\n'.format(cat_array.shape))\n",
    "        for data_slice in cat_array:\n",
    "            np.savetxt(outfile, data_slice, fmt='%-7.2f')\n",
    "            outfile.write('# New slice\\n')\n",
    "    print(\"txt file writing complete\")\n",
    "\n",
    "array_counter = 0\n",
    "test_img = np.empty([test.shape[0], PIXEL, PIXEL])\n",
    "for i in range(test.shape[0]):\n",
    "    convertImageToArray(i)\n",
    "print(\"Test dataset completed\")\n",
    "convertArrayToTxtFile(test_img)\n",
    "print(\"Text file generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read txt files and populate the values into an array (TRAIN)\n",
    "This is for development purposes, where the data preparation and model training is broken up into several phases/session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0] * CAT_COUNT.iloc[0,0]\n",
    "for i in range(1,42):\n",
    "    temp = [i] * CAT_COUNT.iloc[i,0]\n",
    "    y = np.append(y, temp, axis=0)\n",
    "    \n",
    "print(\"Array retrieval complete. y values array size: \", y.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveAllArrayFromFile(array, i):\n",
    "    temp = \"datasets/product detection dataset/train_array/train_img\"\n",
    "    if(i<10):\n",
    "        temp += \"0\"+ str(i) + \".txt\"\n",
    "    else:\n",
    "        temp += str(i) + \".txt\"\n",
    "    temp_data = np.loadtxt(temp)\n",
    "    temp_data = temp_data.reshape((CAT_COUNT.iloc[i,0], PIXEL, PIXEL))\n",
    "    # To set the range of values to be between 0 to 1\n",
    "    temp_data = temp_data / 255.0\n",
    "    if i==0:\n",
    "        return temp_data\n",
    "    else:\n",
    "        return np.append(array, temp_data, axis=0)\n",
    "\n",
    "X1 = 0\n",
    "for i in range(CAT_COUNT.shape[0]):\n",
    "    X1 = retrieveAllArrayFromFile(X1, i)\n",
    "    print(\"X1 category \",i, \": \", X1.shape)\n",
    "        \n",
    "print(\"Array retrieval complete. X1 values array size: \", X1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "The model used is a simple CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential([\n",
    "    #Represents the input layer shape\n",
    "    keras.layers.Flatten(input_shape=(PIXEL, PIXEL)),\n",
    "    #Represents the number of hidden units (hidden layers)\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    # Represents the number of output units (should be consistent with your predicted labels)\n",
    "    keras.layers.Dense(42)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=17)\n",
    "model1.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to remove outliers\n",
    "The model built does not meet the necessary requirements, as such various methods are used to try to improve the accuracy of the model\n",
    "1. Use model to prediction on training dataset\n",
    "2. remove images that where predictions do not align with pre trained model\n",
    "3. use refined dataset to rebuild the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1\n",
    "This method removes all values that when tested on the same trained data does not give the same label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveArrayFromFile1(i, dataset):\n",
    "    temp = \"datasets/product detection dataset/train_array/train_img\"\n",
    "    if(i<10):\n",
    "        temp += \"0\"+ str(i) + \".txt\"\n",
    "    else:\n",
    "        temp += str(i) + \".txt\"\n",
    "    temp_data = np.loadtxt(temp)\n",
    "    temp_data = temp_data.reshape((CAT_COUNT.iloc[i,0], PIXEL, PIXEL))\n",
    "    # To set the range of values to be between 0 to 1\n",
    "    temp_data = temp_data / 255.0\n",
    "    return temp_data\n",
    "\n",
    "def predictionForTrainData1(cat, categoryArray):\n",
    "    probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "    predictions = probability_model.predict(categoryArray)\n",
    "    prediction_label = np.empty(CAT_COUNT.iloc[cat,0])\n",
    "    if(cat<10):\n",
    "        stringCat = \"0\"+str(cat)\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        prediction_label[i] = np.argmax(predictions[i])\n",
    "\n",
    "    catData = train.where(train['category']==cat)\n",
    "    catData = catData.dropna()\n",
    "    catData['prediction'] = pd.Series(prediction_label, index=catData.index)\n",
    "    tempdf = catData.where(catData['prediction']==catData['category'])\n",
    "    return tempdf.dropna()\n",
    "    \n",
    "refined_train1 = pd.DataFrame(columns = ['filename', 'category', 'prediction'])\n",
    "for i in range(42):\n",
    "    categoryArray = retrieveArrayFromFile1(i, 1)\n",
    "    refined_train1 = refined_train1.append(predictionForTrainData1(i, categoryArray))\n",
    "    \n",
    "REFINED_CAT_COUNT1 = refined_train1.groupby(['category']).count()\n",
    "print(refined_train1.shape)\n",
    "REFINED_CAT_COUNT1.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "Initial dataset was unbalanced, this is done to balance the number of images across all label types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category completed: \n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, "
     ]
    }
   ],
   "source": [
    "def dataAugmentation(img_array, i):\n",
    "    #Flip codes\n",
    "    extra_img = cv2.flip(img_array, -1)\n",
    "    new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "    training_data.append([new_array, i])\n",
    "    extra_img = cv2.flip(img_array, 0)\n",
    "    new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "    training_data.append([new_array, i])\n",
    "    extra_img = cv2.flip(img_array, 1)\n",
    "    new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "    training_data.append([new_array, i])\n",
    "\n",
    "training_data = []\n",
    "print('category completed: ')\n",
    "for i in range(42):\n",
    "    if i<10:\n",
    "        cat = \"0\"+str(i)\n",
    "    else:\n",
    "        cat = str(i)\n",
    "    path = os.path.join(\"datasets/product detection dataset/train/\", cat)\n",
    "    counter = 0\n",
    "    for img in os.listdir(path):        \n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        new_array = cv2.resize(img_array, (PIXEL, PIXEL))\n",
    "        training_data.append([new_array, i])\n",
    "        #dataAugmentation(img_array, i)\n",
    "        \n",
    "        if i == 33:\n",
    "            for j in range(3):\n",
    "                blur_factor = j*2+1\n",
    "                extra_img = cv2.GaussianBlur(img_array, (blur_factor,blur_factor), cv2.BORDER_DEFAULT)\n",
    "                new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "                training_data.append([new_array, i])\n",
    "                #dataAugmentation(extra_img, i)\n",
    "        if i == 17 and counter%3<2:\n",
    "            extra_img = cv2.GaussianBlur(img_array, (3,3), cv2.BORDER_DEFAULT)\n",
    "            new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "            training_data.append([new_array, i])\n",
    "            #dataAugmentation(extra_img, i)\n",
    "        if (i == 11 or i == 37) and counter%2<1:\n",
    "            extra_img = cv2.GaussianBlur(img_array, (3,3), cv2.BORDER_DEFAULT)\n",
    "            new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "            training_data.append([new_array, i])\n",
    "            #dataAugmentation(extra_img, i)\n",
    "        if (i == 18 or i == 29) and counter%4<1:\n",
    "            extra_img = cv2.GaussianBlur(img_array, (3,3), cv2.BORDER_DEFAULT)\n",
    "            new_array = cv2.resize(extra_img, (PIXEL, PIXEL))\n",
    "            training_data.append([new_array, i])\n",
    "            #dataAugmentation(extra_img, i)\n",
    "    print(i, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "X2 = []\n",
    "y2 = []\n",
    "for features, label in training_data:\n",
    "    X2.append(features)\n",
    "    y2.append(label)\n",
    "X2 = np.array(X2).reshape(-1, PIXEL, PIXEL, 1)\n",
    "y2 = np.array(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(test.shape[0]):        \n",
    "    img_array = cv2.imread(os.path.join(\"datasets/product detection dataset/test\", test.iloc[i,0]), cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (PIXEL, PIXEL))\n",
    "    test_data.append([new_array])\n",
    "test_data = np.array(test_data).reshape(-1, PIXEL, PIXEL, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An alternative dataset preparation using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"datasets/product detection dataset/X.pickle\",\"wb\")\n",
    "pickle.dump(X2, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open(\"datasets/product detection dataset/y.pickle\",\"wb\")\n",
    "pickle.dump(y2, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"datasets/product detection dataset/test.pickle\",\"wb\")\n",
    "pickle.dump(test_data, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved model\n",
    "This was the final model used, including more layers in the CNN model with dropout functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104832 samples, validate on 11648 samples\n",
      "Epoch 1/30\n",
      "104832/104832 [==============================] - 421s 4ms/sample - loss: 3.4721 - accuracy: 0.0954 - val_loss: 3.1882 - val_accuracy: 0.1700\n",
      "Epoch 2/30\n",
      "104832/104832 [==============================] - 530s 5ms/sample - loss: 3.1851 - accuracy: 0.1646 - val_loss: 3.0300 - val_accuracy: 0.2076\n",
      "Epoch 3/30\n",
      "104832/104832 [==============================] - 374s 4ms/sample - loss: 3.0665 - accuracy: 0.1965 - val_loss: 2.9515 - val_accuracy: 0.2255\n",
      "Epoch 4/30\n",
      "104832/104832 [==============================] - 377s 4ms/sample - loss: 2.9824 - accuracy: 0.2147 - val_loss: 2.8647 - val_accuracy: 0.2468\n",
      "Epoch 5/30\n",
      "104832/104832 [==============================] - 373s 4ms/sample - loss: 2.9264 - accuracy: 0.2288 - val_loss: 2.8306 - val_accuracy: 0.2619\n",
      "Epoch 6/30\n",
      "104832/104832 [==============================] - 371s 4ms/sample - loss: 2.8702 - accuracy: 0.2411 - val_loss: 2.8019 - val_accuracy: 0.2639\n",
      "Epoch 7/30\n",
      "104832/104832 [==============================] - 371s 4ms/sample - loss: 2.8273 - accuracy: 0.2516 - val_loss: 2.7796 - val_accuracy: 0.2708\n",
      "Epoch 8/30\n",
      "104832/104832 [==============================] - 370s 4ms/sample - loss: 2.7806 - accuracy: 0.2632 - val_loss: 2.7445 - val_accuracy: 0.2763\n",
      "Epoch 9/30\n",
      "104832/104832 [==============================] - 371s 4ms/sample - loss: 2.7425 - accuracy: 0.2706 - val_loss: 2.7156 - val_accuracy: 0.2873\n",
      "Epoch 10/30\n",
      "104832/104832 [==============================] - 368s 4ms/sample - loss: 2.7065 - accuracy: 0.2774 - val_loss: 2.7105 - val_accuracy: 0.2858\n",
      "Epoch 11/30\n",
      "104832/104832 [==============================] - 368s 4ms/sample - loss: 2.6710 - accuracy: 0.2862 - val_loss: 2.6918 - val_accuracy: 0.2970\n",
      "Epoch 12/30\n",
      "104832/104832 [==============================] - 367s 3ms/sample - loss: 2.6353 - accuracy: 0.2945 - val_loss: 2.6780 - val_accuracy: 0.2964\n",
      "Epoch 13/30\n",
      "104832/104832 [==============================] - 368s 4ms/sample - loss: 2.6013 - accuracy: 0.3008 - val_loss: 2.6814 - val_accuracy: 0.2935\n",
      "Epoch 14/30\n",
      "104832/104832 [==============================] - 365s 3ms/sample - loss: 2.5684 - accuracy: 0.3070 - val_loss: 2.6785 - val_accuracy: 0.2994\n",
      "Epoch 15/30\n",
      "104832/104832 [==============================] - 366s 3ms/sample - loss: 2.5343 - accuracy: 0.3137 - val_loss: 2.6785 - val_accuracy: 0.2995\n",
      "Epoch 16/30\n",
      "104832/104832 [==============================] - 366s 3ms/sample - loss: 2.5079 - accuracy: 0.3186 - val_loss: 2.6600 - val_accuracy: 0.3037\n",
      "Epoch 17/30\n",
      "104832/104832 [==============================] - 366s 3ms/sample - loss: 2.4827 - accuracy: 0.3266 - val_loss: 2.6496 - val_accuracy: 0.3094\n",
      "Epoch 18/30\n",
      "104832/104832 [==============================] - 364s 3ms/sample - loss: 2.4476 - accuracy: 0.3328 - val_loss: 2.6534 - val_accuracy: 0.3091\n",
      "Epoch 19/30\n",
      "104832/104832 [==============================] - 364s 3ms/sample - loss: 2.4212 - accuracy: 0.3391 - val_loss: 2.6713 - val_accuracy: 0.3102\n",
      "Epoch 20/30\n",
      "104832/104832 [==============================] - 365s 3ms/sample - loss: 2.3931 - accuracy: 0.3425 - val_loss: 2.6590 - val_accuracy: 0.3136\n",
      "Epoch 21/30\n",
      "104832/104832 [==============================] - 374s 4ms/sample - loss: 2.3667 - accuracy: 0.3503 - val_loss: 2.6614 - val_accuracy: 0.3124\n",
      "Epoch 22/30\n",
      "104832/104832 [==============================] - 398s 4ms/sample - loss: 2.3414 - accuracy: 0.3547 - val_loss: 2.6647 - val_accuracy: 0.3112\n",
      "Epoch 23/30\n",
      " 38176/104832 [=========>....................] - ETA: 4:08 - loss: 2.2992 - accuracy: 0.3632"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "X2 = pickle.load(open(\"datasets/product detection dataset/X.pickle\", \"rb\"))\n",
    "y2 = pickle.load(open(\"datasets/product detection dataset/y.pickle\", \"rb\"))\n",
    "\n",
    "X2 = X2/255.0\n",
    "y2 = np.array(y2)\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(128, (3,3), input_shape=(PIXEL, PIXEL, 1)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Conv2D(256, (5,5)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(42))\n",
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X2, y2, batch_size=32, epochs=30, validation_split=0.1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with new dataset\n",
    "If the code below fails, check that the REFINED_CAT_COUNT does not have any missing data. It renders this PIXEL value invalid, therefore pls adjust model or PIXEl variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y2 = [0] * REFINED_CAT_COUNT2.iloc[0,0]\n",
    "\n",
    "for i in range(1,42):\n",
    "    temp = [i] * REFINED_CAT_COUNT2.iloc[i,0]\n",
    "    y2 = np.append(y2, temp, axis=0)\n",
    "    \n",
    "X2 = np.empty([refined_train2.shape[0], PIXEL, PIXEL])\n",
    "for i in range(refined_train2.shape[0]):\n",
    "    X2[i] = X1[refined_train2.index[i]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2, random_state=17)\n",
    "model.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to predict with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.loadtxt(\"datasets/product detection dataset/test_img.txt\")\n",
    "#For model1\n",
    "#test_data = test_data.reshape((test.shape[0], PIXEL, PIXEL))\n",
    "#For model2\n",
    "test_data = pickle.load(open(\"datasets/product detection dataset/test.pickle\", \"rb\"))\n",
    "# To set the range of values to be between 0 to 1\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "probability_model = tf.keras.Sequential([model2, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create results and put in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(test.shape)\n",
    "test_label = np.empty([predictions.shape[0]])\n",
    "for i in range(predictions.shape[0]):\n",
    "    test_label[i] = np.argmax(predictions[i])\n",
    "test['category'] = pd.Series(test_label, index=test.index)\n",
    "test['category']= test['category'].astype(str)\n",
    "test['category'] = test['category'].apply(lambda x: x.zfill(4))\n",
    "test['category'] = test['category'].apply(lambda x: x[:-2])\n",
    "#test.groupby(['category']).count().head(50)\n",
    "test.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('datasets/product detection dataset/results_'+str(PIXEL)+\"px.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
